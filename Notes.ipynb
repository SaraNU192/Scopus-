{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    #url = f'https://api.elsevier.com/content/search/author?co-author=(57062645000)&apiKey=3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "def extract_coauthors_info(author_data):\n",
    "    if 'search-results' in author_data:\n",
    "        author_info = author_data['search-results']['opensearch:Query']\n",
    "        coauthors_info = []\n",
    "        if '@searchTerms' in author_info:\n",
    "            documents = author_info['@searchTerms']\n",
    "            print(documents)\n",
    "            for document in documents:\n",
    "                coauthors_info.append({'coauthor_id': document})\n",
    "    \n",
    "        return coauthors_info\n",
    "    else:\n",
    "        return None, []\n",
    "\n",
    "def save_coauthors_to_csv(coauthors_info, output_file):\n",
    "    data = []\n",
    "    for coauthor in coauthors_info:\n",
    "        data.append([coauthor])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Co-author IDs'])\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors_info.csv'\n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "\n",
    "        if coauthors_info:\n",
    "            save_coauthors_to_csv(coauthors_info, output_file)\n",
    "            print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "        else:\n",
    "            print(\"No co-authors found for the author.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(data)\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_coauthors_info(author_data):\n",
    "    author_ids = []\n",
    "        \n",
    "    if 'search-results' in author_data and 'opensearch:Query'in author_data['search-results']:\n",
    "        entries = author_data['search-results']['opensearch:Query']\n",
    "        \n",
    "        for entry in entries:\n",
    "            if '@searchTerms' in entry:\n",
    "                author_ids.append(entries['@searchTerms'])\n",
    "    \n",
    "    for i in author_ids:\n",
    "        if 'OR' in i:\n",
    "            i.replace(\"OR\", ',')\n",
    "    return author_ids\n",
    "\n",
    "\n",
    "def save_coauthors_to_csv(coauthors_info, output_file):\n",
    "    if not coauthors_info:\n",
    "        print(\"No co-authors found for the author.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(coauthors_info)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors_info.csv'\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "        \n",
    "        if coauthors_info is not None:\n",
    "            save_coauthors_to_csv(coauthors_info, output_file)\n",
    "        else:\n",
    "            print(\"Failed to extract co-authors' information.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_coauthors_info(author_data):\n",
    "    author_ids = []\n",
    "        \n",
    "    if 'search-results' in author_data and 'opensearch:Query' in author_data['search-results']:\n",
    "        query_info = author_data['search-results']['opensearch:Query']\n",
    "        search_terms = query_info.get('@searchTerms', '')\n",
    "        \n",
    "        # Split the search terms by \"OR\" to extract author IDs\n",
    "        author_ids = [term.strip() for term in search_terms.split('OR')]\n",
    "    \n",
    "    # Replace \"OR\" with \",\" in each author ID\n",
    "    author_ids = [author_id.replace(\"OR\", \",\") for author_id in author_ids]\n",
    "    \n",
    "    return author_ids\n",
    "\n",
    "def save_coauthors_to_csv(coauthors_info, output_file):\n",
    "    if not coauthors_info:\n",
    "        print(\"No co-authors found for the author.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame({'Co-author IDs': coauthors_info})\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors_info.csv'\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "        \n",
    "        if coauthors_info is not None:\n",
    "            save_coauthors_to_csv(coauthors_info, output_file)\n",
    "        else:\n",
    "            print(\"Failed to extract co-authors' information.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_coauthors_info(author_data):\n",
    "    author_ids = []\n",
    "        \n",
    "    if 'search-results' in author_data and 'opensearch:Query' in author_data['search-results']:\n",
    "        query_info = author_data['search-results']['opensearch:Query']\n",
    "        search_terms = query_info.get('@searchTerms', '')\n",
    "        \n",
    "        # Split the search terms by \"OR\" to extract author IDs\n",
    "        author_ids = [term.strip() for term in search_terms.split('OR')]\n",
    "    \n",
    "    # Replace \"OR\" with \",\" in each author ID and remove \"au-id(\"\n",
    "    cleaned_author_ids = []\n",
    "    for author_id in author_ids:\n",
    "        cleaned_author_id = author_id.replace(\"OR\", \",\").replace(\"au-id(\", \"\").replace(\")\", \"\").replace(\"(\",\"\")\n",
    "        cleaned_author_ids.append(cleaned_author_id)\n",
    "    # cleaned_author_ids = [str(author_id) for author_id in coauthors_info]\n",
    "    return cleaned_author_ids\n",
    "\n",
    "def save_coauthors_to_csv(coauthors_info, output_file):\n",
    "    if not coauthors_info:\n",
    "        print(\"No co-authors found for the author.\")\n",
    "        return\n",
    "    cleaned_author_ids = [str(author_id) for author_id in coauthors_info]\n",
    "    df = pd.DataFrame({'Co-author IDs': cleaned_author_ids})\n",
    "    df['Co-author IDs'] = df['Co-author IDs'].astype(str)\n",
    "    df.to_excel(output_file)  \n",
    "    print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors.csv'\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "        \n",
    "        if coauthors_info is not None:\n",
    "            save_coauthors_to_csv(coauthors_info, output_file)\n",
    "        else:\n",
    "            print(\"Failed to extract co-authors' information.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_given_names(author_data):\n",
    "    given_names = []\n",
    "    if 'search-results' in author_data and 'entry' in author_data['search-results']:\n",
    "        entries = author_data['search-results']['entry']\n",
    "        for entry in entries:\n",
    "            preferred_name = entry.get('preferred-name', {})\n",
    "            given_name = preferred_name.get('given-name', '')\n",
    "            if given_name:\n",
    "                given_names.append(given_name)\n",
    "    return given_names\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        given_names = extract_given_names(author_data)\n",
    "        if given_names:\n",
    "            print(\"Given Names:\")\n",
    "            for name in given_names:\n",
    "                print(name)\n",
    "        else:\n",
    "            print(\"No given names found.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_coauthors_info(author_data):\n",
    "    author_ids = []\n",
    "        \n",
    "    if 'search-results' in author_data and 'opensearch:Query' in author_data['search-results']:\n",
    "        query_info = author_data['search-results']['opensearch:Query']\n",
    "        search_terms = query_info.get('@searchTerms', '')\n",
    "        \n",
    "        # Split the search terms by \"OR\" to extract author IDs\n",
    "        author_ids = [term.strip() for term in search_terms.split('OR')]\n",
    "    \n",
    "    # Replace \"OR\" with \",\" in each author ID and remove \"au-id(\"\n",
    "    cleaned_author_ids = []\n",
    "    for author_id in author_ids:\n",
    "        cleaned_author_id = author_id.replace(\"OR\", \",\").replace(\"au-id(\", \"\").replace(\")\", \"\").replace(\"(\",\"\")\n",
    "        cleaned_author_ids.append(cleaned_author_id)\n",
    "    # cleaned_author_ids = [str(author_id) for author_id in coauthors_info]\n",
    "    return cleaned_author_ids\n",
    "\n",
    "def save_coauthors_to_csv(coauthors_info, output_file):\n",
    "    if not coauthors_info:\n",
    "        print(\"No co-authors found for the author.\")\n",
    "        return\n",
    "    cleaned_author_ids = [str(author_id) for author_id in coauthors_info]\n",
    "    df = pd.DataFrame({'Co-author IDs': cleaned_author_ids})\n",
    "    df['Co-author IDs'] = df['Co-author IDs'].astype(str)\n",
    "    df.to_excel(output_file)  \n",
    "    print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors.csv'\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "        \n",
    "        if coauthors_info is not None:\n",
    "            save_coauthors_to_csv(coauthors_info, output_file)\n",
    "        else:\n",
    "            print(\"Failed to extract co-authors' information.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_info(author_id, api_key):\n",
    "    url = f'https://api.elsevier.com/content/search/author?co-author={author_id}'\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(\"Good response\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Failed to retrieve author information. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def extract_coauthors_info(author_data):\n",
    "    author_ids = []\n",
    "        \n",
    "    if 'search-results' in author_data and 'opensearch:Query' in author_data['search-results']:\n",
    "        query_info = author_data['search-results']['opensearch:Query']\n",
    "        search_terms = query_info.get('@searchTerms', '')\n",
    "        \n",
    "        # Split the search terms by \"OR\" to extract author IDs\n",
    "        author_ids = [term.strip() for term in search_terms.split('OR')]\n",
    "    \n",
    "    # Replace \"OR\" with \",\" in each author ID and remove \"au-id(\"\n",
    "    cleaned_author_ids = [author_id.replace(\"OR\", \",\").replace(\"au-id(\", \"\").replace(\")\", \"\").replace(\"(\",\"\") for author_id in author_ids]\n",
    "    \n",
    "    return cleaned_author_ids\n",
    "\n",
    "def save_coauthors_to_excel(coauthors_info, output_file):\n",
    "    if not coauthors_info:\n",
    "        print(\"No co-authors found for the author.\")\n",
    "        return\n",
    "    \n",
    "    # Convert coauthors_info to DataFrame with \"Co-author IDs\" column\n",
    "    df = pd.DataFrame({'Co-author IDs': coauthors_info})\n",
    "    \n",
    "    # Convert \"Co-author IDs\" column to string to ensure string representation in Excel\n",
    "    df['Co-author IDs'] = df['Co-author IDs'].astype(str)\n",
    "    \n",
    "    # Save DataFrame to Excel file\n",
    "    df.to_excel(output_file, index=False)  # Specify index=False to exclude row numbers\n",
    "    \n",
    "    print(f\"Co-authors' information saved to '{output_file}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    api_key = '3334155c411aa69fa7f1328e0c50ad7c'\n",
    "    author_id = '57062645000'\n",
    "    output_file = 'coauthors.xlsx'  # Change the file extension to .xlsx for Excel format\n",
    "    \n",
    "    author_data = get_author_info(author_id, api_key)\n",
    "    \n",
    "    if author_data:\n",
    "        coauthors_info = extract_coauthors_info(author_data)\n",
    "        \n",
    "        if coauthors_info is not None:\n",
    "            save_coauthors_to_excel(coauthors_info, output_file)\n",
    "        else:\n",
    "            print(\"Failed to extract co-authors' information.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve author information.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "def extract_first_column_values(file_path):\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        first_column_values = df.iloc[:, 0].tolist()\n",
    "        return first_column_values\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting first column values: {e}\")\n",
    "        return None\n",
    "ids= []\n",
    "excel_file_path = \"/Users/nu/Documents/GitHub/Scopus-/coauthors.xlsx\"\n",
    "first_column_values = extract_first_column_values(excel_file_path)\n",
    "if first_column_values:\n",
    "    print(\"First Column Values:\")\n",
    "    for value in first_column_values:\n",
    "        ids.append(value)\n",
    "else:\n",
    "    print(\"Failed to extract first column values.\")\n",
    "\n",
    "print(ids)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"author id\", \"author name\", \"author indexed name\"])\n",
    "for i in ids:\n",
    "    author = i\n",
    "    url = f\" https://api.elsevier.com/content/author/author_id/{i}?apiKey=af1361e4e58683804f723b56fed20175\"\n",
    "    api_key = \"89a1ebfbce5e0a87b9c189b908fed168\"\n",
    "    headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    while response.status_code != 200:\n",
    "        url = f\" https://api.elsevier.com/content/author/author_id/{i}?apiKey=af1361e4e58683804f723b56fed20175\"\n",
    "        api_key = \"89a1ebfbce5e0a87b9c189b908fed168\"\n",
    "        headers = {'Accept': 'application/json', 'X-ELS-APIKey': api_key}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(url)\n",
    "        print(response)\n",
    "                 \n",
    "    else:\n",
    "        data = response.json()\n",
    "\n",
    "    author_responses = data.get('author-retrieval-response', [])\n",
    "    \n",
    "    for author_data in author_responses:\n",
    "        if 'author-profile' in author_data:\n",
    "            profile = author_data['author-profile']\n",
    "            if 'preferred-name' in profile:\n",
    "                preferred_name = profile['preferred-name']\n",
    "                given_name = preferred_name.get('given-name', '')\n",
    "                surname = preferred_name.get('surname', '')\n",
    "                full_name = f\"{given_name} {surname}\"\n",
    "                print(\"Full Name:\", full_name)\n",
    "            if 'name-variant' in profile:\n",
    "                name_variants = profile['name-variant']\n",
    "                if isinstance(name_variants, list) and len(name_variants) > 0:\n",
    "                    # Iterate over the first two indexed names\n",
    "                    for idx, name_variant in enumerate(name_variants[:2]):\n",
    "                        indexed_given_name = name_variant.get('given-name', '')\n",
    "                        indexed_surname = name_variant.get('surname', '')\n",
    "                        indexed_full_name = f\"{indexed_given_name} {indexed_surname}\"\n",
    "                        print(f\"Indexed Name {idx + 1}:\", indexed_full_name)\n",
    "                elif isinstance(name_variants, dict):\n",
    "                    \n",
    "                    indexed_given_name = name_variants.get('given-name', '')\n",
    "                    indexed_surname = name_variants.get('surname', '')\n",
    "                    indexed_full_name = f\"{indexed_given_name} {indexed_surname}\"\n",
    "                comma = ', '.join(indexed_full_name)\n",
    "        else:\n",
    "            print(\"Author profile not found for author ID:\", i)\n",
    "        try:\n",
    "            org = author_data['author-profile']['affiliation-current']['affiliation']['ip-doc']['org-domain']\n",
    "            print(\"domain\", org)\n",
    "        except TypeError:\n",
    "            org = ' '\n",
    " \n",
    "\n",
    "    row_data = {\n",
    "        \"author id\": str(author),\n",
    "        \"author name\": full_name,\n",
    "        \"author indexed name\": comma\n",
    "    }\n",
    "    df = df._append(row_data, ignore_index=True)\n",
    "    df.to_excel('co-author.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googlesearch import search\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "df = pd.DataFrame(columns=[\"emails\"])\n",
    "# Load the Excel file\n",
    "data = pd.read_excel('co-author.xlsx')\n",
    "\n",
    "def find_first_url(query):\n",
    "    # Get the first result from Google search\n",
    "    for url in search(query, num_results=1):\n",
    "        print(url)\n",
    "        return url\n",
    "    return None\n",
    "\n",
    "def scrape_for_emails(url):\n",
    "    # Send a request to the URL and parse for emails\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        emails = [line for line in text.split() if '@' in line]\n",
    "        return emails\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching emails from {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Dictionary to hold results\n",
    "results = {}\n",
    "\n",
    "# Loop over each search query in the DataFrame\n",
    "for query in data['search_by'].dropna():\n",
    "    first_url = find_first_url(query)\n",
    "    if first_url:\n",
    "        emails = scrape_for_emails(first_url)\n",
    "        results[query] = emails\n",
    "        \n",
    "    else:\n",
    "        results[query] = \"No URL found\"\n",
    "    time.sleep(5) \n",
    "\n",
    "# Display the results\n",
    "for query, emails in results.items():\n",
    "    print(f\"Query: {query}, Emails: {emails}\")\n",
    "    row_data = {\n",
    "    \"email\":emails,\n",
    "\n",
    "}\n",
    "\n",
    "    df = df._append(row_data, ignore_index=True)\n",
    "    df.to_excel('emails.xlsx')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
